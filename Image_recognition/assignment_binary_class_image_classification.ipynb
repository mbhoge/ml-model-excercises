{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2beae8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "588925b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f370d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d9cd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(folder_path):\n",
    "    # Get all JPG files in the folder\n",
    "    jpg_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.jpg')]\n",
    "\n",
    "    # Sort JPG files in alphabetical order\n",
    "    jpg_files.sort()\n",
    "\n",
    "    # Rename JPG files with sequence from English alphabet\n",
    "    for i, filename in enumerate(jpg_files):\n",
    "        new_filename = chr(i+65) + 'img.jpg'\n",
    "        os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e4e768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_dir = 'Photographs\\\\Photographs\\\\train'\n",
    "test_dir = 'Photographs\\\\Photographs\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66912306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename_files('Photographs\\\\Photographs\\\\train\\\\indoor\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32b6f15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indoor\n",
      "outdoor\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(train_dir)\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b144042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 389 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19509014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 95 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c655036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_generator(lambda: train_generator,\n",
    "#                                               output_types=(tf.float32, tf.float32),\n",
    "#                                               output_shapes=([None, 224, 224, 3], [None, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "311fa906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a705611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6687 - accuracy: 0.5604WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "20/20 [==============================] - 8s 338ms/step - loss: 0.6687 - accuracy: 0.5604 - val_loss: 0.6543 - val_accuracy: 0.5263\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 6s 265ms/step - loss: 0.5926 - accuracy: 0.6658\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 6s 272ms/step - loss: 0.4755 - accuracy: 0.7918\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 5s 264ms/step - loss: 0.4057 - accuracy: 0.8149\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 5s 273ms/step - loss: 0.3249 - accuracy: 0.8535\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 5s 277ms/step - loss: 0.2999 - accuracy: 0.8843\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 6s 298ms/step - loss: 0.2787 - accuracy: 0.8817\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 6s 270ms/step - loss: 0.3124 - accuracy: 0.8509\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 7s 335ms/step - loss: 0.2254 - accuracy: 0.9203\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 7s 340ms/step - loss: 0.2246 - accuracy: 0.9152\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 8s 366ms/step - loss: 0.1827 - accuracy: 0.9280\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 8s 417ms/step - loss: 0.1866 - accuracy: 0.9332\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 8s 393ms/step - loss: 0.2160 - accuracy: 0.9306\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 8s 401ms/step - loss: 0.1724 - accuracy: 0.9409\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 8s 391ms/step - loss: 0.1378 - accuracy: 0.9512\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 8s 391ms/step - loss: 0.1614 - accuracy: 0.9280\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 8s 370ms/step - loss: 0.1186 - accuracy: 0.9589\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 9s 426ms/step - loss: 0.1624 - accuracy: 0.9383\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 8s 395ms/step - loss: 0.0948 - accuracy: 0.9743\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 8s 407ms/step - loss: 0.1510 - accuracy: 0.9486\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=20,\n",
    "      epochs=20,\n",
    "      validation_data=test_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fe7dc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/50 [=>............................] - ETA: 8s - loss: 0.1911 - accuracy: 0.9125WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1666 - accuracy: 0.9263\n",
      "Test accuracy: 0.9263157844543457\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=50)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "607f86ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "# Define the path to the image file\n",
    "img_path = os.path.join(cwd, \"Photographs\\\\Photographs\\\\validation\\\\indoor\", \"images284.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80be0259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manish_Bhoge\\OneDrive - EPAM\\Tut\\IITG-TSW-AIML\\Course Assignments & Demo Projects\\ml-model-excercises\\Image_recognition\\Photographs\\Photographs\\validation\\indoor\\images284.jpg\n"
     ]
    }
   ],
   "source": [
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24bb17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = keras.preprocessing.image.load_img(img_path, target_size=(150, 150))\n",
    "image = keras.preprocessing.image.img_to_array(image)\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "image = image.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7b4eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24d56b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00526189]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa3c3c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images259.jpg: indoor\n"
     ]
    }
   ],
   "source": [
    "predicted_label = 'indoor' if prediction < 0.5 else 'outdoor'\n",
    "print(f'{filename}: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2abf15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
